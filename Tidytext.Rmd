# The tidy text format

As described by Hadley Wickham (Wickham 2014), tidy data has a specific structure:

* Each variable is a column
* Each observation is a row
* Each type of observational unit is a table

Tidy text format as being a table with one-token-per-row.

Token

* meaningful unit of text
* word, n-gram, sentence, or paragraph

Tokenization is the process of splitting text into tokens.

## The unnest_tokens function

```{r,cache=TRUE, message=FALSE, warning=FALSE}

library(tidyverse)
library(tidytext)

text <- c("Because I could not stop for Death -",
          "He kindly stopped for me -",
          "The Carriage held but just Ourselves -",
          "and Immortality")


text  ## Check the text

text_df <- data_frame(line = 1:4, text = text)
text_df
text_df  # check the dataframe

```

We need to convert this so that it has one-token-per-document-per-row. 

```{r,cache=TRUE, message=FALSE, warning=FALSE}

text_df %>% unnest_tokens(word,text)

```

* Other columns, such as the line number each word came from, are retained.
* Punctuation has been stripped.
* By default, unnest_tokens() converts the tokens to lowercase, which makes them easier to compare or combine with other datasets. (Use the to_lower = FALSE argument to turn off this behavior).

## Tidying the works of Jane Austen

```{r,cache=TRUE, message=FALSE, warning=FALSE}

library(janeaustenr)

austen_books()

original_books <- austen_books() %>%
  group_by(book) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
                                                 ignore_case = TRUE)))) %>%
  ungroup()

original_books

```

